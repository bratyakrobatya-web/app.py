import streamlit as st  
import requests  
import pandas as pd  
from rapidfuzz import fuzz, process  
import io  
import re
import zipfile
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã  
st.set_page_config(  
    page_title="–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ç–æ—Ä –≥–µ–æ HH.ru",  
    page_icon="üåç",  
    layout="wide"  
)  

# CSS –¥–ª—è –∞–Ω–∏–º–∞—Ü–∏–∏ –∑–µ–º–ª–∏ –∏ —Å—Ç–∏–ª–µ–π  
st.markdown("""  
<style>  
@keyframes rotate {  
    from { transform: rotate(0deg); }  
    to { transform: rotate(360deg); }  
}  

.rotating-earth {  
    display: inline-block;  
    animation: rotate 3s linear infinite;  
    font-size: 3em;  
    vertical-align: middle;  
    margin-right: 15px;  
}  

.main-title {  
    display: inline-block;  
    font-size: 3em;  
    font-weight: bold;  
    vertical-align: middle;  
    margin: 0;  
}  

.title-container {  
    display: flex;  
    align-items: center;  
    margin-bottom: 20px;  
}  
</style>  
""", unsafe_allow_html=True)  

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è session_state  
if 'result_df' not in st.session_state:  
    st.session_state.result_df = None  
if 'duplicate_count' not in st.session_state:  
    st.session_state.duplicate_count = 0  
if 'processed' not in st.session_state:  
    st.session_state.processed = False  
if 'manual_selections' not in st.session_state:  
    st.session_state.manual_selections = {}  
if 'candidates_cache' not in st.session_state:  
    st.session_state.candidates_cache = {}  
if 'search_query' not in st.session_state:  
    st.session_state.search_query = ""
if 'added_cities' not in st.session_state:
    st.session_state.added_cities = []
if 'original_df' not in st.session_state:
    st.session_state.original_df = None

# ============================================  
# –°–ü–†–ê–í–û–ß–ù–ò–ö –§–ï–î–ï–†–ê–õ–¨–ù–´–• –û–ö–†–£–ì–û–í –ò –†–ï–ì–ò–û–ù–û–í  
# ============================================  
FEDERAL_DISTRICTS = {
    "–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥": [
        "–ë–µ–ª–≥–æ—Ä–æ–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–ë—Ä—è–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–í–ª–∞–¥–∏–º–∏—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å",
        "–í–æ—Ä–æ–Ω–µ–∂—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–ò–≤–∞–Ω–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–ö–∞–ª—É–∂—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å",
        "–ö–æ—Å—Ç—Ä–æ–º—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–ö—É—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–õ–∏–ø–µ—Ü–∫–∞—è –æ–±–ª–∞—Å—Ç—å",
        "–ú–æ—Å–∫–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–û—Ä–ª–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–†—è–∑–∞–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å",
        "–°–º–æ–ª–µ–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–¢–∞–º–±–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–¢–≤–µ—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å",
        "–¢—É–ª—å—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–Ø—Ä–æ—Å–ª–∞–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–ú–æ—Å–∫–≤–∞"
    ],
    "–Æ–∂–Ω—ã–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥": [
        "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ê–¥—ã–≥–µ—è", "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ö–∞–ª–º—ã–∫–∏—è", "–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä—Å–∫–∏–π –∫—Ä–∞–π",
        "–ê—Å—Ç—Ä–∞—Ö–∞–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–í–æ–ª–≥–æ–≥—Ä–∞–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–†–æ—Å—Ç–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å"
    ],
    "–°–µ–≤–µ—Ä–æ-–ó–∞–ø–∞–¥–Ω—ã–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥": [
        "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ö–∞—Ä–µ–ª–∏—è", "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ö–æ–º–∏", "–ê—Ä—Ö–∞–Ω–≥–µ–ª—å—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å",
        "–í–æ–ª–æ–≥–æ–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–ö–∞–ª–∏–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–õ–µ–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å",
        "–ú—É—Ä–º–∞–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–ù–æ–≤–≥–æ—Ä–æ–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–ü—Å–∫–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å",
        "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "–ù–µ–Ω–µ—Ü–∫–∏–π –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –æ–∫—Ä—É–≥"
    ],
    "–î–∞–ª—å–Ω–µ–≤–æ—Å—Ç–æ—á–Ω—ã–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥": [
        "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –°–∞—Ö–∞ (–Ø–∫—É—Ç–∏—è)", "–ö–∞–º—á–∞—Ç—Å–∫–∏–π –∫—Ä–∞–π", "–ü—Ä–∏–º–æ—Ä—Å–∫–∏–π –∫—Ä–∞–π",
        "–•–∞–±–∞—Ä–æ–≤—Å–∫–∏–π –∫—Ä–∞–π", "–ê–º—É—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–ú–∞–≥–∞–¥–∞–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å",
        "–°–∞—Ö–∞–ª–∏–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–ï–≤—Ä–µ–π—Å–∫–∞—è –∞–≤—Ç–æ–Ω–æ–º–Ω–∞—è –æ–±–ª–∞—Å—Ç—å", "–ß—É–∫–æ—Ç—Å–∫–∏–π –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –æ–∫—Ä—É–≥"
    ],
    "–°–∏–±–∏—Ä—Å–∫–∏–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥": [
        "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ê–ª—Ç–∞–π", "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ë—É—Ä—è—Ç–∏—è", "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –¢—ã–≤–∞",
        "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –•–∞–∫–∞—Å–∏—è", "–ê–ª—Ç–∞–π—Å–∫–∏–π –∫—Ä–∞–π", "–ó–∞–±–∞–π–∫–∞–ª—å—Å–∫–∏–π –∫—Ä–∞–π",
        "–ö—Ä–∞—Å–Ω–æ—è—Ä—Å–∫–∏–π –∫—Ä–∞–π", "–ò—Ä–∫—É—Ç—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–ö–µ–º–µ—Ä–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å",
        "–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–û–º—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–¢–æ–º—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å"
    ],
    "–£—Ä–∞–ª—å—Å–∫–∏–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥": [
        "–ö—É—Ä–≥–∞–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–°–≤–µ—Ä–¥–ª–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–¢—é–º–µ–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å",
        "–ß–µ–ª—è–±–∏–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–•–∞–Ω—Ç—ã-–ú–∞–Ω—Å–∏–π—Å–∫–∏–π –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –æ–∫—Ä—É–≥ ‚Äî –Æ–≥—Ä–∞",
        "–Ø–º–∞–ª–æ-–ù–µ–Ω–µ—Ü–∫–∏–π –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –æ–∫—Ä—É–≥"
    ],
    "–ü—Ä–∏–≤–æ–ª–∂—Å–∫–∏–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥": [
        "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ë–∞—à–∫–æ—Ä—Ç–æ—Å—Ç–∞–Ω", "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ú–∞—Ä–∏–π –≠–ª", "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ú–æ—Ä–¥–æ–≤–∏—è",
        "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –¢–∞—Ç–∞—Ä—Å—Ç–∞–Ω", "–£–¥–º—É—Ä—Ç—Å–∫–∞—è –†–µ—Å–ø—É–±–ª–∏–∫–∞", "–ß—É–≤–∞—à—Å–∫–∞—è –†–µ—Å–ø—É–±–ª–∏–∫–∞",
        "–ö–∏—Ä–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–ù–∏–∂–µ–≥–æ—Ä–æ–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–û—Ä–µ–Ω–±—É—Ä–≥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å",
        "–ü–µ–Ω–∑–µ–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–ü–µ—Ä–º—Å–∫–∏–π –∫—Ä–∞–π", "–°–∞–º–∞—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å",
        "–°–∞—Ä–∞—Ç–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å", "–£–ª—å—è–Ω–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å"
    ],
    "–°–µ–≤–µ—Ä–æ-–ö–∞–≤–∫–∞–∑—Å–∫–∏–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥": [
        "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –î–∞–≥–µ—Å—Ç–∞–Ω", "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ò–Ω–≥—É—à–µ—Ç–∏—è", "–ö–∞–±–∞—Ä–¥–∏–Ω–æ-–ë–∞–ª–∫–∞—Ä—Å–∫–∞—è –†–µ—Å–ø—É–±–ª–∏–∫–∞",
        "–ö–∞—Ä–∞—á–∞–µ–≤–æ-–ß–µ—Ä–∫–µ—Å—Å–∫–∞—è –†–µ—Å–ø—É–±–ª–∏–∫–∞", "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –°–µ–≤–µ—Ä–Ω–∞—è –û—Å–µ—Ç–∏—è ‚Äî –ê–ª–∞–Ω–∏—è",
        "–ß–µ—á–µ–Ω—Å–∫–∞—è –†–µ—Å–ø—É–±–ª–∏–∫–∞", "–°—Ç–∞–≤—Ä–æ–ø–æ–ª—å—Å–∫–∏–π –∫—Ä–∞–π"
    ],
    "–ö—Ä—ã–º—Å–∫–∏–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥": [
        "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ö—Ä—ã–º", "–°–µ–≤–∞—Å—Ç–æ–ø–æ–ª—å"
    ]
}

# ============================================
# –°–ü–†–ê–í–û–ß–ù–ò–ö –ü–†–ï–î–ü–û–ß–¢–ò–¢–ï–õ–¨–ù–´–• –°–û–í–ü–ê–î–ï–ù–ò–ô
# ============================================
PREFERRED_MATCHES = {
    '–∏–≤–∞–Ω–æ–≤–æ': '–ò–≤–∞–Ω–æ–≤–æ (–ò–≤–∞–Ω–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å)',
    '–∫–∏—Ä–æ–≤': '–ö–∏—Ä–æ–≤ (–ö–∏—Ä–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å)',
    '–ø–æ–¥–æ–ª—å—Å–∫': '–ü–æ–¥–æ–ª—å—Å–∫ (–ú–æ—Å–∫–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å)',
    '—Ç—Ä–æ–∏—Ü–∫': '–¢—Ä–æ–∏—Ü–∫ (–ú–æ—Å–∫–≤–∞)',
    '–∂–µ–ª–µ–∑–Ω–æ–≥–æ—Ä—Å–∫': '–ñ–µ–ª–µ–∑–Ω–æ–≥–æ—Ä—Å–∫ (–ö—Ä–∞—Å–Ω–æ—è—Ä—Å–∫–∏–π –∫—Ä–∞–π)',
    '–∫–∏—Ä–æ–≤—Å–∫': '–ö–∏—Ä–æ–≤—Å–∫ (–õ–µ–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å)',
    '–∏—Å—Ç—Ä–∞': '–ò—Å—Ç—Ä–∞ (–ú–æ—Å–∫–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å)',
    '–∫—Ä–∞—Å–Ω–æ–≥–æ—Ä—Å–∫': '–ö—Ä–∞—Å–Ω–æ–≥–æ—Ä—Å–∫ (–ú–æ—Å–∫–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å)',
}

# ============================================  
# –§–£–ù–ö–¶–ò–ò  
# ============================================  
def normalize_city_name(text):
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞: —ë->–µ, –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä, —É–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã"""
    if not text:
        return ""
    # –ó–∞–º–µ–Ω—è–µ–º —ë –Ω–∞ –µ
    text = text.replace('—ë', '–µ').replace('–Å', '–ï')
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    text = text.lower().strip()
    # –ó–∞–º–µ–Ω—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –Ω–∞ –æ–¥–∏–Ω
    text = re.sub(r'\s+', ' ', text)
    return text

@st.cache_data(ttl=3600)  
def get_hh_areas():  
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ HH.ru"""  
    response = requests.get('https://api.hh.ru/areas')  
    data = response.json()  
      
    areas_dict = {}  
      
    def parse_areas(areas, parent_name="", parent_id="", root_parent_id=""):  
        for area in areas:  
            area_id = area['id']  
            area_name = area['name']  
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤–æ–π parent_id (—Å—Ç—Ä–∞–Ω—É)
            current_root_id = root_parent_id if root_parent_id else parent_id if parent_id else area_id
              
            areas_dict[area_name] = {  
                'id': area_id,  
                'name': area_name,  
                'parent': parent_name,
                'parent_id': parent_id,
                'root_parent_id': current_root_id  # ID —Å—Ç—Ä–∞–Ω—ã –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è
            }  
              
            if area.get('areas'):  
                parse_areas(area['areas'], area_name, area_id, current_root_id)  
      
    parse_areas(data)  
    return areas_dict  

def get_cities_by_regions(hh_areas, selected_regions):
    """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –≥–æ—Ä–æ–¥–∞ –∏–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤ (—Ç–æ–ª—å–∫–æ –†–æ—Å—Å–∏—è, —Ç–æ–ª—å–∫–æ –≥–æ—Ä–æ–¥–∞)"""
    cities = []
    
    # –°–ø–∏—Å–æ–∫ –∏—Å–∫–ª—é—á–µ–Ω–∏–π - —á—Ç–æ –Ω–µ –≤—ã–≥—Ä—É–∂–∞—Ç—å (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è)
    excluded_names_normalized = [
        normalize_city_name('–†–æ—Å—Å–∏—è'),
        normalize_city_name('–î—Ä—É–≥–∏–µ —Ä–µ–≥–∏–æ–Ω—ã'),
        normalize_city_name('–î—Ä—É–≥–∏–µ —Å—Ç—Ä–∞–Ω—ã'),
        normalize_city_name('–ß—É–∫–æ—Ç—Å–∫–∏–π –ê–û'),
        normalize_city_name('–Ø–º–∞–ª–æ-–ù–µ–Ω–µ—Ü–∫–∏–π –ê–û'),
        normalize_city_name('–ù–µ–Ω–µ—Ü–∫–∏–π –ê–û'),
        normalize_city_name('–•–∞–Ω—Ç—ã-–ú–∞–Ω—Å–∏–π—Å–∫–∏–π –ê–û - –Æ–≥—Ä–∞'),
        normalize_city_name('–ï–≤—Ä–µ–π—Å–∫–∞—è –ê–û'),
        normalize_city_name('–ë–µ–ª–æ–≤—Å–∫–æ–µ'),
        normalize_city_name('–ì–æ—Ä—å–∫–∞—è –ë–∞–ª–∫–∞')
    ]
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ —Ä–µ–≥–∏–æ–Ω, –∞ –Ω–µ –≥–æ—Ä–æ–¥
    region_keywords = ['–æ–±–ª–∞—Å—Ç—å', '–∫—Ä–∞–π', '—Ä–µ—Å–ø—É–±–ª–∏–∫–∞', '–æ–∫—Ä—É–≥', '–∞–≤—Ç–æ–Ω–æ–º–Ω']
    
    # ID –†–æ—Å—Å–∏–∏
    russia_id = '113'
    
    for city_name, city_info in hh_areas.items():
        parent = city_info['parent']
        root_parent_id = city_info.get('root_parent_id', '')
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Å—ë, —á—Ç–æ –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –†–æ—Å—Å–∏–∏
        if root_parent_id != russia_id:
            continue
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
        city_name_normalized = normalize_city_name(city_name)
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ)
        if city_name_normalized in excluded_names_normalized:
            continue
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±–ª–∞—Å—Ç–∏, –∫—Ä–∞—è, —Ä–µ—Å–ø—É–±–ª–∏–∫–∏
        if not parent or parent == '–†–æ—Å—Å–∏—è':
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –æ–±–ª–∞—Å—Ç—å—é/–∫—Ä–∞–µ–º/—Ä–µ—Å–ø—É–±–ª–∏–∫–æ–π –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
            is_region = any(keyword in city_name_normalized for keyword in region_keywords)
            if is_region:
                continue
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ "–ê–û" –∏ —ç—Ç–æ –Ω–µ –≥–æ—Ä–æ–¥
            if city_name.endswith(' –ê–û') or city_name.endswith('–ê–û'):
                continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—Ö–æ–¥–∏—Ç –ª–∏ –≥–æ—Ä–æ–¥ –≤ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —Ä–µ–≥–∏–æ–Ω—ã
        for region in selected_regions:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            region_normalized = normalize_city_name(region)
            parent_normalized = normalize_city_name(parent) if parent else ""
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
            if (region_normalized in parent_normalized or 
                parent_normalized in region_normalized or
                region_normalized == parent_normalized or
                region_normalized == city_name_normalized):
                cities.append({
                    '–ì–æ—Ä–æ–¥': city_name,
                    'ID HH': city_info['id'],
                    '–†–µ–≥–∏–æ–Ω': parent if parent else '–†–æ—Å—Å–∏—è'
                })
                break
    
    # –°–æ–∑–¥–∞–µ–º DataFrame
    df = pd.DataFrame(cities)
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é –≥–æ—Ä–æ–¥–∞
    if not df.empty:
        df['_–≥–æ—Ä–æ–¥_normalized'] = df['–ì–æ—Ä–æ–¥'].apply(normalize_city_name)
        df = df.drop_duplicates(subset=['_–≥–æ—Ä–æ–¥_normalized'], keep='first')
        df = df.drop(columns=['_–≥–æ—Ä–æ–¥_normalized'])
    
    return df

def get_all_cities(hh_areas):
    """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –≥–æ—Ä–æ–¥–∞ –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ HH (—Ç–æ–ª—å–∫–æ –†–æ—Å—Å–∏—è, —Ç–æ–ª—å–∫–æ –≥–æ—Ä–æ–¥–∞)"""
    cities = []
    
    # –°–ø–∏—Å–æ–∫ –∏—Å–∫–ª—é—á–µ–Ω–∏–π - —á—Ç–æ –Ω–µ –≤—ã–≥—Ä—É–∂–∞—Ç—å (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è)
    excluded_names_normalized = [
        normalize_city_name('–†–æ—Å—Å–∏—è'),
        normalize_city_name('–î—Ä—É–≥–∏–µ —Ä–µ–≥–∏–æ–Ω—ã'),
        normalize_city_name('–î—Ä—É–≥–∏–µ —Å—Ç—Ä–∞–Ω—ã'),
        normalize_city_name('–ß—É–∫–æ—Ç—Å–∫–∏–π –ê–û'),
        normalize_city_name('–Ø–º–∞–ª–æ-–ù–µ–Ω–µ—Ü–∫–∏–π –ê–û'),
        normalize_city_name('–ù–µ–Ω–µ—Ü–∫–∏–π –ê–û'),
        normalize_city_name('–•–∞–Ω—Ç—ã-–ú–∞–Ω—Å–∏–π—Å–∫–∏–π –ê–û - Yug—Ä–∞'),
        normalize_city_name('–ï–≤—Ä–µ–π—Å–∫–∞—è –ê–û'),
        normalize_city_name('–ë–µ–ª–æ–≤—Å–∫–æ–µ'),
        normalize_city_name('–ì–æ—Ä—å–∫–∞—è –ë–∞–ª–∫–∞')
    ]
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ —Ä–µ–≥–∏–æ–Ω, –∞ –Ω–µ –≥–æ—Ä–æ–¥
    region_keywords = ['–æ–±–ª–∞—Å—Ç—å', '–∫—Ä–∞–π', '—Ä–µ—Å–ø—É–±–ª–∏–∫–∞', '–æ–∫—Ä—É–≥', '–∞–≤—Ç–æ–Ω–æ–º–Ω']
    
    # ID –†–æ—Å—Å–∏–∏
    russia_id = '113'
    
    for city_name, city_info in hh_areas.items():
        parent = city_info['parent']
        root_parent_id = city_info.get('root_parent_id', '')
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Å—ë, —á—Ç–æ –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –†–æ—Å—Å–∏–∏
        if root_parent_id != russia_id:
            continue
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
        city_name_normalized = normalize_city_name(city_name)
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ)
        if city_name_normalized in excluded_names_normalized:
            continue
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±–ª–∞—Å—Ç–∏, –∫—Ä–∞—è, —Ä–µ—Å–ø—É–±–ª–∏–∫–∏
        if not parent or parent == '–†–æ—Å—Å–∏—è':
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –æ–±–ª–∞—Å—Ç—å—é/–∫—Ä–∞–µ–º/—Ä–µ—Å–ø—É–±–ª–∏–∫–æ–π –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
            is_region = any(keyword in city_name_normalized for keyword in region_keywords)
            if is_region:
                continue
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ "–ê–û" –∏ —ç—Ç–æ –Ω–µ –≥–æ—Ä–æ–¥
            if city_name.endswith(' –ê–û') or city_name.endswith('–ê–û'):
                continue
        
        cities.append({
            '–ì–æ—Ä–æ–¥': city_name,
            'ID HH': city_info['id'],
            '–†–µ–≥–∏–æ–Ω': parent if parent else '–†–æ—Å—Å–∏—è'
        })
    
    # –°–æ–∑–¥–∞–µ–º DataFrame
    df = pd.DataFrame(cities)
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é –≥–æ—Ä–æ–¥–∞
    if not df.empty:
        df['_–≥–æ—Ä–æ–¥_normalized'] = df['–ì–æ—Ä–æ–¥'].apply(normalize_city_name)
        df = df.drop_duplicates(subset=['_–≥–æ—Ä–æ–¥_normalized'], keep='first')
        df = df.drop(columns=['_–≥–æ—Ä–æ–¥_normalized'])
    
    return df

def normalize_region_name(text):  
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""  
    text = normalize_city_name(text)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —Å —ë->–µ
    replacements = {  
        '–ª–µ–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–∞—è': '–ª–µ–Ω–∏–Ω–≥—Ä–∞–¥',  
        '–º–æ—Å–∫–æ–≤—Å–∫–∞—è': '–º–æ—Å–∫–æ–≤',  
        '–∫—É—Ä—Å–∫–∞—è': '–∫—É—Ä—Å–∫',  
        '–∫–µ–º–µ—Ä–æ–≤—Å–∫–∞—è': '–∫–µ–º–µ—Ä–æ–≤',  
        '—Å–≤–µ—Ä–¥–ª–æ–≤—Å–∫–∞—è': '—Å–≤–µ—Ä–¥–ª–æ–≤',  
        '–Ω–∏–∂–µ–≥–æ—Ä–æ–¥—Å–∫–∞—è': '–Ω–∏–∂–µ–≥–æ—Ä–æ–¥',  
        '–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫–∞—è': '–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫',  
        '—Ç–∞–º–±–æ–≤—Å–∫–∞—è': '—Ç–∞–º–±–æ–≤',  
        '–∫—Ä–∞—Å–Ω–æ—è—Ä—Å–∫–∞—è': '–∫—Ä–∞—Å–Ω–æ—è—Ä—Å–∫',  
        '–æ–±–ª–∞—Å—Ç—å': '',  
        '–æ–±–ª': '',  
        '–∫—Ä–∞–π': '',  
        '—Ä–µ—Å–ø—É–±–ª–∏–∫–∞': '',  
        '—Ä–µ—Å–ø': '',  
        '  ': ' '  
    }  
    for old, new in replacements.items():  
        text = text.replace(old, new)  
    return text.strip()  

def extract_city_and_region(text):  
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ –∏ —Ä–µ–≥–∏–æ–Ω–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å —É—á–µ—Ç–æ–º –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤"""  
    text_lower = text.lower()  
    
    # –ü—Ä–µ—Ñ–∏–∫—Å—ã –Ω–∞—Å–µ–ª–µ–Ω–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤
    city_prefixes = ['–≥.', '–ø.', '–¥.', '—Å.', '–ø–æ—Å.', '–¥–µ—Ä.', '—Å–µ–ª–æ', '–≥–æ—Ä–æ–¥', '–ø–æ—Å–µ–ª–æ–∫', '–¥–µ—Ä–µ–≤–Ω—è']
    
    # –£–±–∏—Ä–∞–µ–º –≤—Å—ë –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Ç–∏–ø–∞ "–ò—Å—Ç—Ä–∞, –¥–µ—Ä–µ–≤–Ω—è –ü–æ–∫—Ä–æ–≤—Å–∫–æ–µ")
    if ',' in text:
        text = text.split(',')[0].strip()
      
    region_keywords = [  
        '–æ–±–ª–∞—Å—Ç', '–∫—Ä–∞–π', '—Ä–µ—Å–ø—É–±–ª–∏–∫', '–æ–∫—Ä—É–≥',  
        '–ª–µ–Ω–∏–Ω–≥—Ä–∞–¥', '–º–æ—Å–∫–æ–≤', '–∫—É—Ä—Å–∫', '–∫–µ–º–µ—Ä–æ–≤',  
        '—Å–≤–µ—Ä–¥–ª–æ–≤', '–Ω–∏–∂–µ–≥–æ—Ä–æ–¥', '–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫', '—Ç–∞–º–±–æ–≤',  
        '–∫—Ä–∞—Å–Ω–æ—è—Ä—Å–∫'  
    ]  
    
    # –£–¥–∞–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å—ã –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏ (—Å –ø—Ä–æ–±–µ–ª–æ–º –∏ –±–µ–∑)
    text_cleaned = text.strip()
    for prefix in city_prefixes:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å –ø—Ä–æ–±–µ–ª–æ–º: "–≥. –ú–æ—Å–∫–≤–∞"
        if text_cleaned.lower().startswith(prefix + ' '):
            text_cleaned = text_cleaned[len(prefix) + 1:].strip()  # +1 –¥–ª—è –ø—Ä–æ–±–µ–ª–∞
            break
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑ –ø—Ä–æ–±–µ–ª–∞: "–≥.–ú–æ—Å–∫–≤–∞"
        elif text_cleaned.lower().startswith(prefix):
            text_cleaned = text_cleaned[len(prefix):].strip()
            break
      
    words = text_cleaned.split()  
      
    if len(words) == 1:  
        return text_cleaned, None  
      
    city_words = []  
    region_words = []  
    region_found = False  
      
    for word in words:  
        word_lower = word.lower()  
        if not region_found and any(keyword in word_lower for keyword in region_keywords):  
            region_found = True  
            region_words.append(word)  
        elif region_found:  
            region_words.append(word)  
        else:  
            city_words.append(word)  
      
    city = ' '.join(city_words) if city_words else text_cleaned  
    region = ' '.join(region_words) if region_words else None  
      
    return city, region  

def check_if_changed(original, matched):  
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∏–∑–º–µ–Ω–∏–ª–æ—Å—å –ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞"""  
    if matched is None or matched == "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è":  
        return False  
      
    original_clean = original.strip()  
    matched_clean = matched.strip()  
      
    return original_clean != matched_clean  

def get_candidates_by_word(client_city, hh_city_names, limit=20):  
    """–ü–æ–ª—É—á–∞–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Å–ª–æ–≤–∞"""  
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
    if not client_city or not client_city.strip():
        return []
    
    words = client_city.split()
    if not words:
        return []
    
    first_word = normalize_city_name(words[0])  
      
    candidates = []  
    for city_name in hh_city_names:  
        city_lower = normalize_city_name(city_name)  
        if first_word in city_lower:  
            score = fuzz.WRatio(normalize_city_name(client_city), city_lower)  
            candidates.append((city_name, score))  
      
    candidates.sort(key=lambda x: x[1], reverse=True)  
      
    return candidates[:limit]  

def smart_match_city(client_city, hh_city_names, hh_areas, threshold=85):  
    """–£–º–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏ —É—á–µ—Ç–æ–º –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π"""  
      
    city_part, region_part = extract_city_and_region(client_city)  
    city_part_lower = normalize_city_name(city_part)  
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    if city_part_lower in PREFERRED_MATCHES:
        preferred_match = PREFERRED_MATCHES[city_part_lower]
        if preferred_match in hh_city_names:
            score = fuzz.WRatio(city_part_lower, normalize_city_name(preferred_match))
            word_candidates = get_candidates_by_word(city_part, hh_city_names)
            return (preferred_match, score, 0), word_candidates
      
    word_candidates = get_candidates_by_word(city_part, hh_city_names)  
      
    if word_candidates and len(word_candidates) > 0 and word_candidates[0][1] >= threshold:  
        best_candidate = word_candidates[0]  
        return (best_candidate[0], best_candidate[1], 0), word_candidates  
      
    if not word_candidates or (word_candidates and word_candidates[0][1] < threshold):  
        return None, word_candidates  
      
    exact_matches = []  
    exact_matches_with_region = []  
      
    for hh_city_name in hh_city_names:  
        hh_city_base = normalize_city_name(hh_city_name.split('(')[0].strip())  
          
        if city_part_lower == hh_city_base:  
            if region_part:  
                region_normalized = normalize_region_name(region_part)  
                hh_normalized = normalize_region_name(hh_city_name)  
                  
                if region_normalized in hh_normalized:  
                    exact_matches_with_region.append(hh_city_name)  
                else:  
                    exact_matches.append(hh_city_name)  
            else:  
                exact_matches.append(hh_city_name)  
      
    if exact_matches_with_region:  
        best_match = exact_matches_with_region[0]  
        score = fuzz.WRatio(city_part_lower, normalize_city_name(best_match))  
        return (best_match, score, 0), word_candidates  
    elif exact_matches:  
        best_match = exact_matches[0]  
        score = fuzz.WRatio(city_part_lower, normalize_city_name(best_match))  
        return (best_match, score, 0), word_candidates  
      
    candidates = process.extract(  
        city_part,  
        hh_city_names,  
        scorer=fuzz.WRatio,  
        limit=10  
    )  
      
    if not candidates:  
        return None, word_candidates  
      
    candidates = [c for c in candidates if c[1] >= threshold]  
      
    if not candidates:  
        return None, word_candidates  
      
    if len(candidates) == 1:  
        return candidates[0], word_candidates  
      
    best_match = None  
    best_score = 0  
      
    for candidate_name, score, _ in candidates:  
        candidate_lower = normalize_city_name(candidate_name)  
        adjusted_score = score  
          
        candidate_city = normalize_city_name(candidate_name.split('(')[0].strip())  
          
        if city_part_lower == candidate_city:  
            adjusted_score += 50  
        elif city_part_lower in candidate_city:  
            adjusted_score += 30  
        elif candidate_city in city_part_lower:  
            adjusted_score += 20  
        else:  
            adjusted_score -= 30  
          
        if region_part:  
            region_normalized = normalize_region_name(region_part)  
            candidate_normalized = normalize_region_name(candidate_name)  
              
            if region_normalized in candidate_normalized:  
                adjusted_score += 40  
            elif '(' in candidate_name:  
                adjusted_score -= 25  
          
        len_diff = abs(len(candidate_city) - len(city_part_lower))  
        if len_diff > 3:  
            adjusted_score -= 20  
          
        if len(candidate_city) > len(city_part_lower) + 4:  
            adjusted_score -= 25  
          
        if len(candidate_name) > 15 and len(city_part) > 15:  
            adjusted_score += 5  
          
        region_keywords = ['oblast', '–∫—Ä–∞–π', '—Ä–µ—Å–ø—É–±–ª–∏–∫', '–æ–∫—Ä—É–≥']  
        client_has_region = any(keyword in city_part_lower for keyword in region_keywords)  
        candidate_has_region = any(keyword in candidate_lower for keyword in region_keywords)  
          
        if client_has_region and candidate_has_region:  
            adjusted_score += 15  
        elif client_has_region and not candidate_has_region:  
            adjusted_score -= 15  
          
        if adjusted_score > best_score:  
            best_score = adjusted_score  
            best_match = (candidate_name, score, _)  
      
    return (best_match if best_match else candidates[0]), word_candidates  

def match_cities(original_df, hh_areas, threshold=85):  
    """–°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≥–æ—Ä–æ–¥–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏ –≤—Å–µ—Ö —Å—Ç–æ–ª–±—Ü–æ–≤"""  
    results = []  
    hh_city_names = list(hh_areas.keys())  
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤
    first_col_name = original_df.columns[0]
    other_cols = original_df.columns[1:].tolist() if len(original_df.columns) > 1 else []
      
    seen_original_cities = {}  
    seen_hh_cities = {}  
      
    duplicate_original_count = 0  
    duplicate_hh_count = 0  
      
    st.session_state.candidates_cache = {}  
      
    progress_bar = st.progress(0)  
    status_text = st.empty()  
      
    for idx, row in original_df.iterrows():
        progress = (idx + 1) / len(original_df)  
        progress_bar.progress(progress)  
        status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {idx + 1} –∏–∑ {len(original_df)} –≥–æ—Ä–æ–¥–æ–≤...")  
        
        client_city = row[first_col_name]
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
        other_values = {col: row[col] for col in other_cols}
          
        if pd.isna(client_city) or str(client_city).strip() == "":  
            results.append({  
                '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city,  
                '–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ': None,  
                'ID HH': None,  
                '–†–µ–≥–∏–æ–Ω': None,  
                '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': 0,  
                '–ò–∑–º–µ–Ω–µ–Ω–∏–µ': '–ù–µ—Ç',  
                '–°—Ç–∞—Ç—É—Å': '‚ùå –ü—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ',  
                'row_id': idx,
                **other_values  # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
            })  
            continue  
          
        client_city_original = str(client_city).strip()  
        client_city_normalized = normalize_city_name(client_city_original)  
          
        if client_city_normalized in seen_original_cities:  
            duplicate_original_count += 1  
            original_result = seen_original_cities[client_city_normalized]  
            results.append({  
                '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city_original,  
                '–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ': original_result['–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ'],  
                'ID HH': original_result['ID HH'],  
                '–†–µ–≥–∏–æ–Ω': original_result['–†–µ–≥–∏–æ–Ω'],  
                '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': original_result['–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %'],  
                '–ò–∑–º–µ–Ω–µ–Ω–∏–µ': original_result['–ò–∑–º–µ–Ω–µ–Ω–∏–µ'],  
                '–°—Ç–∞—Ç—É—Å': 'üîÑ –î—É–±–ª–∏–∫–∞—Ç (–∏—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ)',  
                'row_id': idx,
                **other_values
            })  
            continue  
          
        match_result, candidates = smart_match_city(client_city_original, hh_city_names, hh_areas, threshold)  
          
        st.session_state.candidates_cache[idx] = candidates  
          
        if match_result:  
            matched_name = match_result[0]  
            score = match_result[1]  
            hh_info = hh_areas[matched_name]  
            hh_city_normalized = normalize_city_name(hh_info['name'])  
              
            is_changed = check_if_changed(client_city_original, hh_info['name'])  
            change_status = '–î–∞' if is_changed else '–ù–µ—Ç'  
              
            if hh_city_normalized in seen_hh_cities:  
                duplicate_hh_count += 1  
                city_result = {  
                    '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city_original,  
                    '–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ': hh_info['name'],  
                    'ID HH': hh_info['id'],  
                    '–†–µ–≥–∏–æ–Ω': hh_info['parent'],  
                    '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': round(score, 1),  
                    '–ò–∑–º–µ–Ω–µ–Ω–∏–µ': change_status,  
                    '–°—Ç–∞—Ç—É—Å': 'üîÑ –î—É–±–ª–∏–∫–∞—Ç (—Ä–µ–∑—É–ª—å—Ç–∞—Ç HH)',  
                    'row_id': idx,
                    **other_values
                }  
                results.append(city_result)  
                seen_original_cities[client_city_normalized] = city_result  
            else:  
                status = '‚úÖ –¢–æ—á–Ω–æ–µ' if score >= 95 else '‚ö†Ô∏è –ü–æ—Ö–æ–∂–µ–µ'  
                  
                city_result = {  
                    '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city_original,  
                    '–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ': hh_info['name'],  
                    'ID HH': hh_info['id'],  
                    '–†–µ–≥–∏–æ–Ω': hh_info['parent'],  
                    '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': round(score, 1),  
                    '–ò–∑–º–µ–Ω–µ–Ω–∏–µ': change_status,  
                    '–°—Ç–∞—Ç—É—Å': status,  
                    'row_id': idx,
                    **other_values
                }  
                  
                results.append(city_result)  
                seen_original_cities[client_city_normalized] = city_result  
                seen_hh_cities[hh_city_normalized] = True  
        else:  
            city_result = {  
                '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city_original,  
                '–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ': None,  
                'ID HH': None,  
                '–†–µ–≥–∏–æ–Ω': None,  
                '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': 0,  
                '–ò–∑–º–µ–Ω–µ–Ω–∏–µ': '–ù–µ—Ç',  
                '–°—Ç–∞—Ç—É—Å': '‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ',  
                'row_id': idx,
                **other_values
            }  
              
            results.append(city_result)  
            seen_original_cities[client_city_normalized] = city_result  
      
    progress_bar.empty()  
    status_text.empty()  
      
    total_duplicates = duplicate_original_count + duplicate_hh_count  
      
    return pd.DataFrame(results), duplicate_original_count, duplicate_hh_count, total_duplicates  

# ============================================  
# –ò–ù–¢–ï–†–§–ï–ô–°  
# ============================================  
# –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∑–µ–º–ª–µ–π  
st.markdown(  
    '<div class="title-container">'  
    '<span class="rotating-earth">üåç</span>'  
    '<span class="main-title">–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ç–æ—Ä –≥–µ–æ HH.ru</span>'  
    '</div>',  
    unsafe_allow_html=True  
)  
st.markdown("---")  

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ HH
try:  
    hh_areas = get_hh_areas()  
except Exception as e:  
    st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞: {str(e)}")  
    hh_areas = None  

# ============================================
# –ë–õ–û–ö: –ü–†–û–í–ï–†–ö–ê –ì–ï–û
# ============================================
if hh_areas:
    st.header("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–µ–æ")
    st.info("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –Ω–∞–ø–∏—Å–∞–Ω–∏–µ –≤ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–µ HH.ru")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –≥–æ—Ä–æ–¥–∞ –†–æ—Å—Å–∏–∏
        russia_cities = []
        for city_name, city_info in hh_areas.items():
            if city_info.get('root_parent_id') == '113':
                russia_cities.append(city_name)
        
        search_geo = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ—Ä–æ–¥ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:",
            options=[""] + sorted(russia_cities),
            key="geo_checker",
            help="–ù–∞—á–Ω–∏—Ç–µ –≤–≤–æ–¥–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞"
        )
    
    with col2:
        if search_geo:
            city_info = hh_areas[search_geo]
            st.success("‚úÖ –ù–∞–π–¥–µ–Ω–æ")
            st.info(f"**ID HH:** {city_info['id']}")
            st.info(f"**–†–µ–≥–∏–æ–Ω:** {city_info['parent']}")

st.markdown("---")

# ============================================
# –ë–õ–û–ö: –°–ò–ù–•–†–û–ù–ò–ó–ê–¢–û–† –ì–û–†–û–î–û–í
# ============================================
st.header("üì§ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ç–æ—Ä –≥–æ—Ä–æ–¥–æ–≤")

with st.sidebar:  
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")  
    threshold = st.slider(  
        "–ü–æ—Ä–æ–≥ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (%)",  
        min_value=50,  
        max_value=100,  
        value=85,  
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"  
    )  
      
    st.markdown("---")  
      
    st.markdown("### üìñ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è")  
    st.markdown("""  
    **–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**  
      
    1. **–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª** Excel –∏–ª–∏ CSV —Å –≥–æ—Ä–æ–¥–∞–º–∏  
    2. –ì–æ—Ä–æ–¥–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ **–ø–µ—Ä–≤–æ–π –∫–æ–ª–æ–Ω–∫–µ**  
    3. –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã —Å–æ—Ö—Ä–∞–Ω—è—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    4. –ù–∞–∂–º–∏—Ç–µ **"üöÄ –ù–∞—á–∞—Ç—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ"**  
    5. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ç–∞–±–ª–∏—Ü–µ  
    6. –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –≥–æ—Ä–æ–¥–∞ —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º ‚â§ 90%  
    7. –î–æ–±–∞–≤—å—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≥–æ—Ä–æ–¥–∞ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    8. –°–∫–∞—á–∞–π—Ç–µ –∏—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª  
      
    **–§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞:**  
    - –ü–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü - –≥–æ—Ä–æ–¥–∞  
    - –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã - –ª—é–±—ã–µ –¥–∞–Ω–Ω—ã–µ
    - –ú–æ–∂–Ω–æ —É–∫–∞–∑—ã–≤–∞—Ç—å –æ–±–ª–∞—Å—Ç—å/—Ä–µ–≥–∏–æ–Ω  
    - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –ø—Ä–µ—Ñ–∏–∫—Å—ã: –≥., –ø., –¥., —Å.
    """)  
      
    st.markdown("---")  
    st.markdown("### üìä –°—Ç–∞—Ç—É—Å—ã")  
    st.markdown("""  
    - ‚úÖ **–¢–æ—á–Ω–æ–µ** - —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ ‚â•95%  
    - ‚ö†Ô∏è **–ü–æ—Ö–æ–∂–µ–µ** - —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ ‚â•–ø–æ—Ä–æ–≥–∞  
    - üîÑ **–î—É–±–ª–∏–∫–∞—Ç** - –ø–æ–≤—Ç–æ—Ä—ã  
    - ‚ùå **–ù–µ –Ω–∞–π–¥–µ–Ω–æ** - —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ <–ø–æ—Ä–æ–≥–∞  
    """)  

col1, col2 = st.columns([1, 1])  

with col1:  
    st.subheader("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞")  
    uploaded_file = st.file_uploader(  
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —Å –≥–æ—Ä–æ–¥–∞–º–∏",  
        type=['xlsx', 'csv'],  
        help="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç—ã: Excel (.xlsx) –∏ CSV"  
    )  
      
    with st.expander("üìã –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä —Ñ–æ—Ä–º–∞—Ç–∞ —Ñ–∞–π–ª–∞"):  
        example_df = pd.DataFrame({  
            '–ì–æ—Ä–æ–¥': ['–≥. –ú–æ—Å–∫–≤–∞', '–ø. –í–Ω—É–∫–æ–≤—Å–∫–æ–µ', '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥', '–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥'],
            '–î–∞–Ω–Ω—ã–µ 1': ['–ó–Ω–∞—á–µ–Ω–∏–µ 1', '–ó–Ω–∞—á–µ–Ω–∏–µ 2', '–ó–Ω–∞—á–µ–Ω–∏–µ 3', '–ó–Ω–∞—á–µ–Ω–∏–µ 4'],
            '–î–∞–Ω–Ω—ã–µ 2': ['A', 'B', 'C', 'D']
        })  
        st.dataframe(example_df, use_container_width=True, hide_index=True)
        st.caption("‚úÖ –ü–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü - –≥–æ—Ä–æ–¥–∞ (—Å –ø—Ä–µ—Ñ–∏–∫—Å–∞–º–∏ –≥., –ø. –∏ –¥—Ä.)")
        st.caption("‚úÖ –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π")

with col2:  
    st.subheader("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")  
    if hh_areas:
        st.success(f"‚úÖ –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ HH –∑–∞–≥—Ä—É–∂–µ–Ω: **{len(hh_areas)}** –≥–æ—Ä–æ–¥–æ–≤")  

if uploaded_file is not None and hh_areas is not None:  
    st.markdown("---")  
      
    try:  
        if uploaded_file.name.endswith('.csv'):  
            df = pd.read_csv(uploaded_file, header=None)  
        else:  
            df = pd.read_excel(uploaded_file, header=None)  
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã
        has_header = False
        has_vacancy_column = False
        vacancy_col_idx = None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        if len(df) > 0:
            first_row = df.iloc[0]
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—É—é —è—á–µ–π–∫—É –Ω–∞ "–ì–æ—Ä–æ–¥"
            if pd.notna(first_row[0]) and '–≥–æ—Ä–æ–¥' in str(first_row[0]).lower():
                has_header = True
                # –ò—â–µ–º —Å—Ç–æ–ª–±–µ—Ü "–í–∞–∫–∞–Ω—Å–∏—è"
                for idx, val in enumerate(first_row):
                    if pd.notna(val) and '–≤–∞–∫–∞–Ω—Å–∏—è' in str(val).lower():
                        has_vacancy_column = True
                        vacancy_col_idx = idx
                        break
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫, —É–¥–∞–ª—è–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∏ –¥–µ–ª–∞–µ–º –µ—ë –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
        if has_header:
            df.columns = df.iloc[0]
            df = df.iloc[1:].reset_index(drop=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π DataFrame
        st.session_state.original_df = df.copy()
        st.session_state.has_vacancy_mode = has_vacancy_column
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–≤—å—é —Ñ–∞–π–ª–∞
        if has_vacancy_column:
            st.info(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ **{len(df)}** —Å—Ç—Ä–æ–∫, **{len(df.columns)}** —Å—Ç–æ–ª–±—Ü–æ–≤ | üéØ **–†–µ–∂–∏–º: –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≤–∞–∫–∞–Ω—Å–∏—è–º**")
        else:
            st.info(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ **{len(df)}** —Å—Ç—Ä–æ–∫, **{len(df.columns)}** —Å—Ç–æ–ª–±—Ü–æ–≤")
        
        with st.expander("üëÄ –ü—Ä–µ–≤—å—é –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫)"):
            st.dataframe(df.head(), use_container_width=True)
          
        if st.button("üöÄ –ù–∞—á–∞—Ç—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ", type="primary", use_container_width=True):  
            with st.spinner("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é..."):  
                result_df, dup_original, dup_hh, total_dup = match_cities(df, hh_areas, threshold)  
                st.session_state.result_df = result_df  
                st.session_state.dup_original = dup_original  
                st.session_state.dup_hh = dup_hh  
                st.session_state.total_dup = total_dup  
                st.session_state.processed = True  
                st.session_state.manual_selections = {}  
                st.session_state.search_query = ""
                st.session_state.added_cities = []
          
        if st.session_state.processed and st.session_state.result_df is not None:  
            result_df = st.session_state.result_df.copy()  
            dup_original = st.session_state.dup_original  
            dup_hh = st.session_state.dup_hh  
            total_dup = st.session_state.total_dup  
              
            st.markdown("---")  
            st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã")  
              
            col1, col2, col3, col4, col5, col6 = st.columns(6)  
              
            total = len(result_df)  
            exact = len(result_df[result_df['–°—Ç–∞—Ç—É—Å'] == '‚úÖ –¢–æ—á–Ω–æ–µ'])  
            similar = len(result_df[result_df['–°—Ç–∞—Ç—É—Å'] == '‚ö†Ô∏è –ü–æ—Ö–æ–∂–µ–µ'])  
            duplicates = len(result_df[result_df['–°—Ç–∞—Ç—É—Å'].str.contains('–î—É–±–ª–∏–∫–∞—Ç', na=False)])  
            not_found = len(result_df[result_df['–°—Ç–∞—Ç—É—Å'] == '‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ'])  
              
            to_export = len(result_df[  
                (~result_df['–°—Ç–∞—Ç—É—Å'].str.contains('–î—É–±–ª–∏–∫–∞—Ç', na=False)) &   
                (result_df['–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ'].notna())  
            ])  
              
            col1.metric("–í—Å–µ–≥–æ", total)  
            col2.metric("‚úÖ –¢–æ—á–Ω—ã—Ö", exact)  
            col3.metric("‚ö†Ô∏è –ü–æ—Ö–æ–∂–∏—Ö", similar)  
            col4.metric("üîÑ –î—É–±–ª–∏–∫–∞—Ç–æ–≤", duplicates)  
            col5.metric("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ", not_found)  
            col6.metric("üì§ –ö –≤—ã–≥—Ä—É–∑–∫–µ", to_export)  
              
            if duplicates > 0:  
                st.warning(f"""  
                ‚ö†Ô∏è **–ù–∞–π–¥–µ–Ω–æ {duplicates} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:**  
                - üîÑ –ü–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é: **{dup_original}**  
                - üîÑ –ü–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É HH: **{dup_hh}**  
                """)  
              
            st.markdown("---")  
            st.subheader("üìã –¢–∞–±–ª–∏—Ü–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–π")  
              
            st.text_input(  
                "üîç –ü–æ–∏—Å–∫ –ø–æ —Ç–∞–±–ª–∏—Ü–µ",  
                key="search_query",
                placeholder="–ù–∞—á–Ω–∏—Ç–µ –≤–≤–æ–¥–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞...",  
                label_visibility="visible"  
            )  
              
            result_df['sort_priority'] = result_df.apply(  
                lambda row: 0 if row['–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %'] == 0 else (1 if row['–ò–∑–º–µ–Ω–µ–Ω–∏–µ'] == '–î–∞' else 2),  
                axis=1  
            )  
              
            result_df_sorted = result_df.sort_values(  
                by=['sort_priority', '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %'],  
                ascending=[True, True]  
            ).reset_index(drop=True)  
              
            if st.session_state.search_query and st.session_state.search_query.strip():  
                search_lower = st.session_state.search_query.lower().strip()  
                mask = result_df_sorted.apply(  
                    lambda row: (  
                        search_lower in str(row['–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ']).lower() or  
                        search_lower in str(row['–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ']).lower() or  
                        search_lower in str(row['–†–µ–≥–∏–æ–Ω']).lower() or  
                        search_lower in str(row['–°—Ç–∞—Ç—É—Å']).lower()  
                    ),  
                    axis=1  
                )  
                result_df_filtered = result_df_sorted[mask]  
                  
                if len(result_df_filtered) == 0:  
                    st.warning(f"–ü–æ –∑–∞–ø—Ä–æ—Å—É **'{st.session_state.search_query}'** –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")  
                else:  
                    st.info(f"–ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: **{len(result_df_filtered)}** –∏–∑ {len(result_df_sorted)}")  
            else:  
                result_df_filtered = result_df_sorted  
              
            display_df = result_df_filtered.copy()  
            display_df = display_df.drop(['row_id', 'sort_priority'], axis=1, errors='ignore')  
              
            st.dataframe(display_df, use_container_width=True, height=400)  
              
            # –ò–ó–ú–ï–ù–ï–ù–û: –ò—Å–∫–ª—é—á–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            editable_rows = result_df_sorted[
                (result_df_sorted['–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %'] <= 90) & 
                (~result_df_sorted['–°—Ç–∞—Ç—É—Å'].str.contains('–î—É–±–ª–∏–∫–∞—Ç', na=False))
            ].copy()  
              
            if len(editable_rows) > 0:  
                st.markdown("---")  
                st.subheader("‚úèÔ∏è –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–æ–≤ —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º ‚â§ 90%")  
                st.info(f"–ù–∞–π–¥–µ–Ω–æ **{len(editable_rows)}** –≥–æ—Ä–æ–¥–æ–≤, –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")  
                  
                # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞
                russia_cities_for_select = []
                for city_name, city_info in hh_areas.items():
                    if city_info.get('root_parent_id') == '113':
                        russia_cities_for_select.append(city_name)
                russia_cities_for_select = sorted(russia_cities_for_select)
                
                for idx, row in editable_rows.iterrows():  
                    with st.container():  
                        col1, col2, col3, col4 = st.columns([2, 3, 1, 1])  
                          
                        with col1:  
                            st.markdown(f"**{row['–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ']}**")  
                          
                        with col2:  
                            row_id = row['row_id']  
                            candidates = st.session_state.candidates_cache.get(row_id, [])  
                            
                            # –ò–ó–ú–ï–ù–ï–ù–û: –ï—Å–ª–∏ –Ω–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–ª–∏ "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ", –¥–∞–µ–º –≤—ã–±–æ—Ä –∏–∑ –≤—Å–µ–≥–æ —Å–ø–∏—Å–∫–∞
                            if not candidates or row['–°—Ç–∞—Ç—É—Å'] == '‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ':
                                options = ["‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"] + russia_cities_for_select
                                
                                current_value = row['–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ']
                                
                                if row_id in st.session_state.manual_selections:
                                    selected_value = st.session_state.manual_selections[row_id]
                                    if selected_value == "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è":
                                        default_idx = 0
                                    else:
                                        try:
                                            default_idx = options.index(selected_value)
                                        except ValueError:
                                            default_idx = 0
                                else:
                                    default_idx = 0
                                    if current_value and current_value in options:
                                        default_idx = options.index(current_value)
                                
                                selected = st.selectbox(
                                    "–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ—Ä–æ–¥:",
                                    options=options,
                                    index=default_idx,
                                    key=f"select_{row_id}",
                                    label_visibility="collapsed"
                                )
                                
                                st.session_state.manual_selections[row_id] = selected
                                
                            else:
                                # –ï—Å—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç—ã - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ö
                                options = ["‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"] + [f"{c[0]} ({c[1]:.1f}%)" for c in candidates]  
                                  
                                current_value = row['–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ']  
                                  
                                if row_id in st.session_state.manual_selections:  
                                    selected_value = st.session_state.manual_selections[row_id]  
                                    if selected_value == "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è":  
                                        default_idx = 0  
                                    else:  
                                        default_idx = 0  
                                        for i, c in enumerate(candidates):  
                                            if c[0] == selected_value:  
                                                default_idx = i + 1  
                                                break  
                                else:  
                                    default_idx = 0  
                                    if current_value:  
                                        for i, c in enumerate(candidates):  
                                            if c[0] == current_value:  
                                                default_idx = i + 1  
                                                break  
                                  
                                selected = st.selectbox(  
                                    "–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ—Ä–æ–¥:",  
                                    options=options,  
                                    index=default_idx,  
                                    key=f"select_{row_id}",  
                                    label_visibility="collapsed"  
                                )  
                                  
                                if selected == "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è":  
                                    st.session_state.manual_selections[row_id] = "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"  
                                else:  
                                    selected_city = selected.rsplit(' (', 1)[0]  
                                    st.session_state.manual_selections[row_id] = selected_city  
                          
                        with col3:  
                            st.text(f"{row['–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %']}%")  
                          
                        with col4:  
                            st.text(row['–°—Ç–∞—Ç—É—Å'])  
                          
                        st.markdown("<hr style='margin-top: 5px; margin-bottom: 5px;'>", unsafe_allow_html=True)  
                  
                if st.session_state.manual_selections:  
                    no_match_count = sum(1 for v in st.session_state.manual_selections.values() if v == "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è")  
                    changed_count = len(st.session_state.manual_selections) - no_match_count  
                      
                    st.success(f"‚úÖ –í–Ω–µ—Å–µ–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {changed_count} | ‚ùå –û—Ç–º–µ—á–µ–Ω–æ –∫–∞–∫ '–ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è': {no_match_count}")  
            
            # ============================================
            # –ë–õ–û–ö: –î–û–ë–ê–í–õ–ï–ù–ò–ï –õ–Æ–ë–û–ì–û –ì–û–†–û–î–ê
            # ============================================
            st.markdown("---")
            st.subheader("‚ûï –î–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≥–æ—Ä–æ–¥–∞")
            st.info("–î–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ –≥–æ—Ä–æ–¥–∞ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–æ–∫–∏ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
            
            col1, col2, col3 = st.columns([3, 1, 1])
            
            with col1:
                # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –≥–æ—Ä–æ–¥–∞ –†–æ—Å—Å–∏–∏ –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞
                russia_cities = []
                for city_name, city_info in hh_areas.items():
                    if city_info.get('root_parent_id') == '113':
                        russia_cities.append(city_name)
                
                selected_city = st.selectbox(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ—Ä–æ–¥:",
                    options=sorted(russia_cities),
                    key="city_selector",
                    help="–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ—Ä–æ–¥ –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ HH.ru"
                )
            
            with col2:
                if st.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å", use_container_width=True, type="primary"):
                    if selected_city and selected_city not in st.session_state.added_cities:
                        st.session_state.added_cities.append(selected_city)
                        st.success(f"‚úÖ {selected_city}")
                    elif selected_city in st.session_state.added_cities:
                        st.warning(f"‚ö†Ô∏è –£–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω")
            
            with col3:
                if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å", use_container_width=True):
                    st.session_state.added_cities = []
                    st.rerun()
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤
            if st.session_state.added_cities:
                st.success(f"üìã –î–æ–±–∞–≤–ª–µ–Ω–æ –≥–æ—Ä–æ–¥–æ–≤: **{len(st.session_state.added_cities)}**")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≥–æ—Ä–æ–¥–∞ –≤ –∫–æ–º–ø–∞–∫—Ç–Ω–æ–º –≤–∏–¥–µ
                added_cities_text = ", ".join(st.session_state.added_cities)
                st.text_area(
                    "–°–ø–∏—Å–æ–∫ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤:",
                    value=added_cities_text,
                    height=100,
                    disabled=True,
                    label_visibility="collapsed"
                )
              
            st.markdown("---")  
            st.subheader("üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")  
              
            final_result_df = result_df.copy()
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä—É—á–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            if st.session_state.manual_selections:  
                for row_id, new_value in st.session_state.manual_selections.items():  
                    mask = final_result_df['row_id'] == row_id  
                      
                    if new_value == "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è":  
                        final_result_df.loc[mask, '–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ'] = None  
                        final_result_df.loc[mask, 'ID HH'] = None  
                        final_result_df.loc[mask, '–†–µ–≥–∏–æ–Ω'] = None  
                        final_result_df.loc[mask, '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %'] = 0  
                        final_result_df.loc[mask, '–ò–∑–º–µ–Ω–µ–Ω–∏–µ'] = '–ù–µ—Ç'  
                        final_result_df.loc[mask, '–°—Ç–∞—Ç—É—Å'] = '‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ'  
                    else:  
                        final_result_df.loc[mask, '–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ'] = new_value  
                          
                        if new_value in hh_areas:  
                            final_result_df.loc[mask, 'ID HH'] = hh_areas[new_value]['id']  
                            final_result_df.loc[mask, '–†–µ–≥–∏–æ–Ω'] = hh_areas[new_value]['parent']  
                          
                        original = final_result_df.loc[mask, '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ'].values[0]  
                        final_result_df.loc[mask, '–ò–∑–º–µ–Ω–µ–Ω–∏–µ'] = '–î–∞' if check_if_changed(original, new_value) else '–ù–µ—Ç'  
            
            # –ü–†–û–í–ï–†–Ø–ï–ú –†–ï–ñ–ò–ú –†–ê–ë–û–¢–´
            if st.session_state.get('has_vacancy_mode', False):
                # –†–ï–ñ–ò–ú: –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≤–∞–∫–∞–Ω—Å–∏—è–º
                st.info("üéØ **–†–µ–∂–∏–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –ø–æ –≤–∞–∫–∞–Ω—Å–∏—è–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω**")
                
                # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤
                original_cols = st.session_state.original_df.columns.tolist()
                
                # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å —Å—Ç–æ–ª–±—Ü–∞ "–í–∞–∫–∞–Ω—Å–∏—è"
                vacancy_col = None
                for col in original_cols:
                    if '–≤–∞–∫–∞–Ω—Å–∏—è' in str(col).lower():
                        vacancy_col = col
                        break
                
                if vacancy_col:
                    # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
                    export_df = final_result_df[
                        (~final_result_df['–°—Ç–∞—Ç—É—Å'].str.contains('–î—É–±–ª–∏–∫–∞—Ç', na=False)) & 
                        (final_result_df['–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ'].notna())
                    ].copy()
                    
                    # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏
                    if vacancy_col in export_df.columns:
                        unique_vacancies = export_df[vacancy_col].dropna().unique()
                        
                        st.success(f"üìä –ù–∞–π–¥–µ–Ω–æ **{len(unique_vacancies)}** —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π")
                        
                        # –°–æ–∑–¥–∞–µ–º ZIP –∞—Ä—Ö–∏–≤ —Å–æ –≤—Å–µ–º–∏ —Ñ–∞–π–ª–∞–º–∏
                        import zipfile
                        from datetime import datetime
                        
                        zip_buffer = io.BytesIO()
                        
                        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                            for vacancy in unique_vacancies:
                                # –§–∏–ª—å—Ç—Ä—É–µ–º –≥–æ—Ä–æ–¥–∞ –ø–æ –≤–∞–∫–∞–Ω—Å–∏–∏
                                vacancy_df = export_df[export_df[vacancy_col] == vacancy].copy()
                                
                                # –ë–µ—Ä–µ–º –≤—Å–µ —Å—Ç–æ–ª–±—Ü—ã –ö–†–û–ú–ï —Å–ª—É–∂–µ–±–Ω—ã—Ö –∏ "–í–∞–∫–∞–Ω—Å–∏—è"
                                # –ó–∞–º–µ–Ω—è–µ–º "–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ" –Ω–∞ "–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ"
                                output_vacancy_df = pd.DataFrame()
                                
                                # –î–æ–±–∞–≤–ª—è–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ –∫–∞–∫ –ø–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü
                                output_vacancy_df[original_cols[0]] = vacancy_df['–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ']
                                
                                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (–∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–≥–æ –∏ –≤–∞–∫–∞–Ω—Å–∏–∏)
                                for col in original_cols[1:]:
                                    if col != vacancy_col and col in vacancy_df.columns:
                                        output_vacancy_df[col] = vacancy_df[col].values
                                
                                # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é –≥–æ—Ä–æ–¥–∞
                                output_vacancy_df['_normalized'] = output_vacancy_df[original_cols[0]].apply(normalize_city_name)
                                output_vacancy_df = output_vacancy_df.drop_duplicates(subset=['_normalized'], keep='first')
                                output_vacancy_df = output_vacancy_df.drop(columns=['_normalized'])
                                
                                # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
                                safe_vacancy_name = str(vacancy).replace('/', '_').replace('\\', '_')[:50]
                                file_name = f"{safe_vacancy_name}.xlsx"
                                
                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±—É—Ñ–µ—Ä –° –ó–ê–ì–û–õ–û–í–ö–ê–ú–ò
                                file_buffer = io.BytesIO()
                                with pd.ExcelWriter(file_buffer, engine='openpyxl') as writer:
                                    output_vacancy_df.to_excel(writer, index=False, header=True, sheet_name='–†–µ–∑—É–ª—å—Ç–∞—Ç')
                                file_buffer.seek(0)
                                
                                # –î–æ–±–∞–≤–ª—è–µ–º –≤ ZIP
                                zip_file.writestr(file_name, file_buffer.getvalue())
                        
                        zip_buffer.seek(0)
                        
                        # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è ZIP
                        st.download_button(
                            label=f"üì¶ –°–∫–∞—á–∞—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã ({len(unique_vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π)",
                            data=zip_buffer,
                            file_name=f"vacancies_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                            mime="application/zip",
                            use_container_width=True,
                            type="primary"
                        )
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–≤—å—é –ø–æ –≤–∞–∫–∞–Ω—Å–∏—è–º
                        with st.expander("üëÄ –ü—Ä–µ–≤—å—é —Ñ–∞–π–ª–æ–≤ –ø–æ –≤–∞–∫–∞–Ω—Å–∏—è–º"):
                            for vacancy in unique_vacancies:
                                vacancy_df = export_df[export_df[vacancy_col] == vacancy].copy()
                                cities_count = len(vacancy_df['–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ'].unique())
                                st.markdown(f"**{vacancy}** - {cities_count} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤")
                
            else:
                # –û–ë–´–ß–ù–´–ô –†–ï–ñ–ò–ú (–∫–∞–∫ –±—ã–ª–æ —Ä–∞–Ω—å—à–µ)
                col1, col2 = st.columns(2)
                
                with col1:  
                    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∞–π–ª –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ç–æ—Ä–∞ —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ —Å—Ç–æ–ª–±—Ü–∞–º–∏
                    # –ò—Å–∫–ª—é—á–∞–µ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∏ –¥—É–±–ª–∏–∫–∞—Ç—ã
                    export_df = final_result_df[
                        (~final_result_df['–°—Ç–∞—Ç—É—Å'].str.contains('–î—É–±–ª–∏–∫–∞—Ç', na=False)) & 
                        (final_result_df['–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ'].notna())
                    ].copy()
                    
                    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                    original_cols = st.session_state.original_df.columns.tolist()
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π DataFrame: –ø–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü - –∏—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ, –æ—Å—Ç–∞–ª—å–Ω—ã–µ - –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                    publisher_df = pd.DataFrame()
                    publisher_df[original_cols[0]] = export_df['–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ']
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                    for col in original_cols[1:]:
                        if col in export_df.columns:
                            publisher_df[col] = export_df[col].values
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≥–æ—Ä–æ–¥–∞ —Å –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–æ–∫–∏
                    if st.session_state.added_cities:
                        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                        last_row_values = st.session_state.original_df.iloc[-1].tolist()
                        
                        for city in st.session_state.added_cities:
                            new_row = [city] + last_row_values[1:]  # –ì–æ—Ä–æ–¥ + –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–æ–∫–∏
                            publisher_df.loc[len(publisher_df)] = new_row
                        
                        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                        publisher_df['_normalized'] = publisher_df[original_cols[0]].apply(normalize_city_name)
                        publisher_df = publisher_df.drop_duplicates(subset=['_normalized'], keep='first')
                        publisher_df = publisher_df.drop(columns=['_normalized'])
                    
                    output_publisher = io.BytesIO()  
                    with pd.ExcelWriter(output_publisher, engine='openpyxl') as writer:  
                        publisher_df.to_excel(writer, index=False, header=False, sheet_name='–†–µ–∑—É–ª—å—Ç–∞—Ç')  
                    output_publisher.seek(0)  
                      
                    publisher_count = len(publisher_df)  
                      
                    st.download_button(  
                        label=f"üì§ –§–∞–π–ª –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ç–æ—Ä–∞\n{publisher_count} —Å—Ç—Ä–æ–∫",  
                        data=output_publisher,  
                        file_name=f"geo_result_{uploaded_file.name.rsplit('.', 1)[0]}.xlsx",  
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",  
                        use_container_width=True,
                        type="primary",
                        key='download_publisher'  
                    )
                    
                    st.caption("‚úÖ –ü–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü –∑–∞–º–µ–Ω–µ–Ω –Ω–∞ –∏—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ")
                    st.caption("‚úÖ –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
                    st.caption("‚úÖ –ò—Å–∫–ª—é—á–µ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∏ –¥—É–±–ª–∏–∫–∞—Ç—ã")
                    if st.session_state.added_cities:
                        st.caption(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –≥–æ—Ä–æ–¥–æ–≤: {len(st.session_state.added_cities)}")
                  
                with col2:  
                    output = io.BytesIO()  
                    export_full_df = final_result_df.drop(['row_id', 'sort_priority'], axis=1, errors='ignore')  
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:  
                        export_full_df.to_excel(writer, index=False, sheet_name='–†–µ–∑—É–ª—å—Ç–∞—Ç')  
                    output.seek(0)  
                      
                    st.download_button(  
                        label="üì• –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç —Å –∞–Ω–∞–ª–∏–∑–æ–º",  
                        data=output,  
                        file_name=f"full_report_{uploaded_file.name.rsplit('.', 1)[0]}.xlsx",  
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",  
                        use_container_width=True,  
                        key='download_full'  
                    )
                    
                    st.caption("üìä –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ –≤—Å–µ–º–∏ –¥–∞–Ω–Ω—ã–º–∏")
                    st.caption("üìä –í–∫–ª—é—á–∞–µ—Ç —Å—Ç–∞—Ç—É—Å—ã –∏ –ø—Ä–æ—Ü–µ–Ω—Ç—ã —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")
      
    except Exception as e:  
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {str(e)}")  
        import traceback  
        st.code(traceback.format_exc())  

st.markdown("---")

# ============================================
# –ë–õ–û–ö: –í–´–ë–û–† –†–ï–ì–ò–û–ù–û–í
# ============================================
st.header("üó∫Ô∏è –í—ã–±–æ—Ä —Ä–µ–≥–∏–æ–Ω–æ–≤")
st.markdown("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –æ–∫—Ä—É–≥–∞ –∏ –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –≥–æ—Ä–æ–¥–æ–≤")

if hh_areas is not None:
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("–§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –æ–∫—Ä—É–≥–∞")
        selected_districts = st.multiselect(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –æ–∫—Ä—É–≥–∞:",
            options=list(FEDERAL_DISTRICTS.keys()),
            help="–ú–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–∫—Ä—É–≥–æ–≤",
            key="districts_select"
        )
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –æ–∫—Ä—É–≥–æ–≤
    available_regions = []
    if selected_districts:
        for district in selected_districts:
            available_regions.extend(FEDERAL_DISTRICTS[district])
    else:
        # –ï—Å–ª–∏ –æ–∫—Ä—É–≥–∞ –Ω–µ –≤—ã–±—Ä–∞–Ω—ã, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ —Ä–µ–≥–∏–æ–Ω—ã
        for regions in FEDERAL_DISTRICTS.values():
            available_regions.extend(regions)
    
    with col2:
        st.subheader("–û–±–ª–∞—Å—Ç–∏/–†–µ–≥–∏–æ–Ω—ã")
        selected_regions = st.multiselect(
            "–í—ã–±–µ—Ä–∏—Ç–µ –æ–±–ª–∞—Å—Ç–∏/—Ä–µ–≥–∏–æ–Ω—ã:",
            options=sorted(available_regions),
            help="–ú–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–≥–∏–æ–Ω–æ–≤",
            key="regions_select"
        )
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–∏–µ —Ä–µ–≥–∏–æ–Ω—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –ø–æ–∏—Å–∫–∞
    regions_to_search = []
    
    # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–≥–∏–æ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
    if selected_regions:
        regions_to_search = selected_regions
    # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω—ã —Ç–æ–ª—å–∫–æ –æ–∫—Ä—É–≥–∞ (–±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤), –±–µ—Ä–µ–º –≤—Å–µ —Ä–µ–≥–∏–æ–Ω—ã –∏–∑ —ç—Ç–∏—Ö –æ–∫—Ä—É–≥–æ–≤
    elif selected_districts:
        for district in selected_districts:
            regions_to_search.extend(FEDERAL_DISTRICTS[district])
    
    # –ö–Ω–æ–ø–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π
    col_btn1, col_btn2 = st.columns(2)
    
    with col_btn1:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –≤—ã–±—Ä–∞–Ω–æ
        if regions_to_search:
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—ã–±–æ—Ä–µ
            if selected_regions:
                st.info(f"üìç –í—ã–±—Ä–∞–Ω–æ —Ä–µ–≥–∏–æ–Ω–æ–≤: **{len(selected_regions)}**")
            elif selected_districts:
                st.info(f"üìç –í—ã–±—Ä–∞–Ω–æ –æ–∫—Ä—É–≥–æ–≤: **{len(selected_districts)}** (–≤–∫–ª—é—á–∞–µ—Ç {len(regions_to_search)} —Ä–µ–≥–∏–æ–Ω–æ–≤)")
            
            if st.button("üîç –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≥–æ—Ä–æ–¥–æ–≤ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º", type="primary", use_container_width=True):
                with st.spinner("–§–æ—Ä–º–∏—Ä—É—é —Å–ø–∏—Å–æ–∫ –≥–æ—Ä–æ–¥–æ–≤..."):
                    cities_df = get_cities_by_regions(hh_areas, regions_to_search)
                    
                    if not cities_df.empty:
                        st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ **{len(cities_df)}** –≥–æ—Ä–æ–¥–æ–≤ –≤ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–∞—Ö")
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
                        st.dataframe(cities_df, use_container_width=True, height=400)
                        
                        # –ö–Ω–æ–ø–∫–∏ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            # –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç
                            output_full = io.BytesIO()
                            with pd.ExcelWriter(output_full, engine='openpyxl') as writer:
                                cities_df.to_excel(writer, index=False, sheet_name='–ì–æ—Ä–æ–¥–∞')
                            output_full.seek(0)
                            
                            st.download_button(
                                label=f"üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç ({len(cities_df)} –≥–æ—Ä–æ–¥–æ–≤)",
                                data=output_full,
                                file_name="cities_full_report.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                use_container_width=True,
                                key="download_regions_full"
                            )
                        
                        with col2:
                            # –¢–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏—è –≥–æ—Ä–æ–¥–æ–≤ –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ç–æ—Ä–∞
                            publisher_df = pd.DataFrame({'–ì–æ—Ä–æ–¥': cities_df['–ì–æ—Ä–æ–¥']})
                            output_publisher = io.BytesIO()
                            with pd.ExcelWriter(output_publisher, engine='openpyxl') as writer:
                                publisher_df.to_excel(writer, index=False, header=False, sheet_name='–ì–µ–æ')
                            output_publisher.seek(0)
                            
                            st.download_button(
                                label=f"üì§ –î–ª—è –ø—É–±–ª–∏–∫–∞—Ç–æ—Ä–∞ ({len(cities_df)} –≥–æ—Ä–æ–¥–æ–≤)",
                                data=output_publisher,
                                file_name="cities_for_publisher.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                use_container_width=True,
                                key="download_regions_publisher"
                            )
                    else:
                        st.warning("‚ö†Ô∏è –ì–æ—Ä–æ–¥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–∞—Ö")
        else:
            st.info("üëÜ –í—ã–±–µ—Ä–∏—Ç–µ —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –æ–∫—Ä—É–≥–∞ –∏–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–≥–∏–æ–Ω—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –≥–æ—Ä–æ–¥–æ–≤")
    
    with col_btn2:
        # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ –≤—Å–µ—Ö –≥–æ—Ä–æ–¥–æ–≤
        if st.button("üåç –í—ã–≥—Ä—É–∑–∏—Ç—å –í–°–ï –≥–æ—Ä–æ–¥–∞ –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞", type="secondary", use_container_width=True):
            with st.spinner("–§–æ—Ä–º–∏—Ä—É—é –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –≥–æ—Ä–æ–¥–æ–≤..."):
                all_cities_df = get_all_cities(hh_areas)
                
                if not all_cities_df.empty:
                    st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ **{len(all_cities_df)}** –≥–æ—Ä–æ–¥–æ–≤ –≤ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–µ HH.ru")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
                    st.dataframe(all_cities_df, use_container_width=True, height=400)
                    
                    # –ö–Ω–æ–ø–∫–∏ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç
                        output_all_full = io.BytesIO()
                        with pd.ExcelWriter(output_all_full, engine='openpyxl') as writer:
                            all_cities_df.to_excel(writer, index=False, sheet_name='–ì–æ—Ä–æ–¥–∞')
                        output_all_full.seek(0)
                        
                        st.download_button(
                            label=f"üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç ({len(all_cities_df)} –≥–æ—Ä–æ–¥–æ–≤)",
                            data=output_all_full,
                            file_name="all_cities_full_report.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True,
                            key="download_all_full"
                        )
                    
                    with col2:
                        # –¢–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏—è –≥–æ—Ä–æ–¥–æ–≤ –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ç–æ—Ä–∞
                        publisher_all_df = pd.DataFrame({'–ì–æ—Ä–æ–¥': all_cities_df['–ì–æ—Ä–æ–¥']})
                        output_all_publisher = io.BytesIO()
                        with pd.ExcelWriter(output_all_publisher, engine='openpyxl') as writer:
                            publisher_all_df.to_excel(writer, index=False, header=False, sheet_name='–ì–µ–æ')
                        output_all_publisher.seek(0)
                        
                        st.download_button(
                            label=f"üì§ –î–ª—è –ø—É–±–ª–∏–∫–∞—Ç–æ—Ä–∞ ({len(all_cities_df)} –≥–æ—Ä–æ–¥–æ–≤)",
                            data=output_all_publisher,
                            file_name="all_cities_for_publisher.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True,
                            key="download_all_publisher"
                        )
                else:
                    st.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≥–æ—Ä–æ–¥–æ–≤")

st.markdown("---")  
st.markdown(  
    "–°–¥–µ–ª–∞–Ω–æ —Å ‚ù§Ô∏è | –î–∞–Ω–Ω—ã–µ –∏–∑ API HH.ru",  
    unsafe_allow_html=True  
)
